# Jarvis - 主动式 AI Agent

## 项目概述

Jarvis 是一个主动式 AI Agent，能够像人一样操作电脑、进行自然语音对话、主动提供帮助。

### 六大核心能力

1. **Computer Use**: Agent 像人一样操作电脑完成任务
2. **自然语音对话**: 可被用户打断，支持多轮对话
3. **主动交互**: 不是一问一答，像真人一样主动说话
4. **意图预测**: 观察并预测用户想做什么，主动提供帮助
5. **独立工作区**: 在虚拟桌面中工作，不干扰用户
6. **长时间工作**: 几小时到几天，不跑偏，不崩溃

## 技术栈

- **框架**: Electron + TypeScript + React
- **UI 风格**: macOS 26 液态玻璃风格
- **构建工具**: Vite
- **测试**: Vitest
- **调试**: electron MCP

## 技术选型

| 组件 | 技术 | 配置 |
|------|------|------|
| 大脑 VLM | 豆包 | API Key: `6b53f54e-11fc-4dee-a1ad-405098a4058d` |
| 大脑 VLM | Qwen3-VL | API Key: `f1181caebae94db6a1ff403625a7d612` |
| 小脑 | MAI-UI-2b | Ollama `localhost:11434`, model: `ahmadwaqar/mai-ui` |
| 语音识别 | 字节流式 ASR | APP ID: `9849623045` |
| 语音合成 | 字节 TTS | 同上 |
| 离线备用 | Vosk + Silero VAD | 本地模型 |
| 桌面自动化 | nut.js + AppleScript + Swift | macOS 专用 |

### 字节语音服务认证
- APP ID: `9849623045`
- Access Token: `06xaC6DV7Wz7dN44DaG1cSw66mtw-1mr`
- Secret Key: `_Sr76vFPwSsmLOQKzkX1NXmtkC39lHLI`

## 项目结构

```
src/main/
├── services/brain/BrainService.ts          # 大脑核心
├── services/cerebellum/CerebellumService.ts # 小脑核心
├── services/operator/OperatorService.ts     # 操作执行
├── services/voice/VoiceService.ts           # 语音交互
├── services/perception/PerceptionService.ts # 感知系统
├── services/workspace/WorkspaceService.ts   # 工作区管理
├── services/task/TaskService.ts             # 任务管理
├── core/AgentLoop.ts                        # 主循环
└── core/StateManager.ts                     # 状态管理

src/renderer/
├── components/dynamic-island/               # 灵动岛组件
│   ├── DynamicIsland.tsx                   # 主组件
│   ├── NotchIntegration.tsx                # 刘海融合
│   ├── BreathingAnimation.tsx              # 呼吸动画
│   └── LiquidMerge.tsx                     # 液态融合效果
├── components/mouse-hint/                   # 鼠标跟随提示
│   ├── MouseHint.tsx                       # 主组件
│   └── FlyToIsland.tsx                     # 飞入动画
├── components/dashboard/                    # 主界面
└── components/voice/                        # 语音面板

native/spaces-control/
└── SpacesControl.swift                      # Spaces 控制
```

## UI 设计规范

### 设计原则
- **液态玻璃风格**: macOS 26 设计语言
- **融入系统**: Agent 与电脑合一，与 macOS 刘海融合
- **人味十足**: 自然、有灵性的交互
- **精致细腻**: 高标准 UI 品质
- **跟随系统**: 自动切换深色/浅色模式

### 灵动岛设计

**位置**: 屏幕顶部中央，包裹 macOS 刘海（notch）
**多显示器**: 用户可选择在哪几块显示器上显示
**位置固定**: 不允许用户拖拽

**状态变化**:
- 休眠态: 与刘海融为一体
- 工作态: 从刘海两侧液态扩展，显示进度和图标
- 通知态: 向下展开通知卡片

**动画效果**:
1. 呼吸动画: 类似 iOS 灵动岛的脉冲/呼吸动画（整体膨胀收缩）
2. 扩展动画: 有任务时从刘海两侧液态扩展
3. 通知展开: 像 iOS 通知一样从灵动岛下方展开（卡片式）
4. 收缩动画: 任务完成后液态收缩回刘海大小

**悬浮交互**:
- 未悬浮: 只显示文字/图标进度
- 悬浮时: 展开显示详细内容 + 实时视频预览
- 点击预览: 观察 agent 操作，显示小白鼠标指针标识操作位置

### 鼠标跟随提示

**视觉风格**: 类似 Spotlight 搜索框（圆角矩形），但更柔和、干扰更弱

**设计要点**:
- 小巧精致，液态玻璃材质
- 智能避让，不遮挡重要内容
- 轻微声音提示（轻柔的"叮"）
- 5秒后自动消失

**飞入融合动画**:
- 用户确认 → 提示框"飞向"灵动岛 → 触碰时像液体融入 → 灵动岛扩展显示任务
- 飞行轨迹要灵动自然（贝塞尔曲线）
- 触碰灵动岛时有液态融合效果

### 交互风格

**简洁高效原则**:
- 不过分简洁: 至少一句话
- 不过分啰嗦: 最多四句话
- 高效: 避免冗余，聚焦行动

**好的响应示例**:
- "已打开 VS Code，正在加载 jarvis 项目。"
- "检测到你在重复复制文件，要我帮你批量处理吗？"
- "任务完成。创建了 3 个文件夹，移动了 15 个文件。"

**避免的响应**:
- 过于简洁: "好。" "完成。"
- 过于啰嗦: "好的，我现在开始帮你打开 VS Code 应用程序。VS Code 是一个非常流行的代码编辑器..."

## 大脑-小脑协作机制

### 通信频率
- 小脑可以**连续执行多步简单操作**
- 只在**关键节点汇报**给大脑
- 执行失败时**立即上报**大脑

### 大脑规划粒度
- 大脑规划到**细粒度**（如"点击搜索框"）
- 每个步骤标记是否可并行预生成

### 并行指令预生成（性能优化）

```
大脑规划输出:
┌─────────────────────────────────────────────────────────┐
│ Step 1: 点击 Chrome 图标        [依赖: 无]    [可并行]    │
│ Step 2: 等待 Chrome 打开        [依赖: Step1] [不可并行]  │
│ Step 3: 点击地址栏              [依赖: Step2] [不可并行]  │
│ Step 4: 输入 "github.com"       [依赖: Step3] [可并行]    │
│ Step 5: 按回车键                [依赖: Step4] [可并行]    │
└─────────────────────────────────────────────────────────┘

小脑执行流程:
执行 Step1 的同时，预生成 Step4、Step5 的指令
(因为它们不依赖 Step1 的执行结果，只依赖前置步骤完成)
```

### 步骤标记协议

```typescript
interface TaskStep {
  id: string;
  description: string;
  dependencies: string[];      // 依赖的前置步骤 ID
  canPregenerate: boolean;     // 大脑标记：是否可以并行预生成
  pregenerateAfter?: string;   // 在哪个步骤之后可以开始预生成
}
```

## 纠偏方案

### 纠偏机制：分叉检查

**核心思想**：每 10 轮对话强制启动一个从当前消息历史分叉的纠偏检查

```
主对话流:
┌─────┐   ┌─────┐   ┌─────┐   ┌─────┐   ┌─────┐
│ M1  │──▶│ M2  │──▶│ M3  │──▶│ ... │──▶│ M10 │
└─────┘   └─────┘   └─────┘   └─────┘   └─────┘
                                            │
                                            ▼ 触发分叉检查
                                      ┌──────────┐
                                      │ 纠偏分支  │
                                      └────┬─────┘
                                           │
                            ┌──────────────┴──────────────┐
                            ▼                              ▼
                      没有偏差                         有偏差
                      ┌────────┐                    ┌────────┐
                      │ 遗弃分支 │                    │ 合并修正 │
                      └────────┘                    └────────┘
```

### 用户介入方式

通过灵动岛提供以下操作选项：
- 继续执行
- 重试当前步骤
- 取消任务
- 手动接管
- 发送新消息

## 用户习惯感知

### 监控范围
- 键盘鼠标操作
- 设备连接（摄像头、麦克风、外接设备等）
- 应用使用
- 窗口切换
- 屏幕截图
- 文件操作

### 习惯学习模型
- 常用应用及使用频率
- 操作模式（如 "打开 VS Code → 打开终端 → 运行 npm"）
- 时间习惯
- 交互偏好（响应长度、主动程度、是否需要确认）

### 习惯数据存储
- 位置: 本地存储
- 加密: 不加密
- 保留: 永久保留
- 用户可手动清空

## 语音系统

### 说话人识别
- 方案: 声纹注册 + 匹配
- 首次使用: 显示一条固定的冷笑话让用户朗读
- 环境要求: 安静环境下录制

### 对话判断
- 无唤醒词，持续后台监听
- 完全由 Agent 根据语义上下文判断
- 结合声纹 + 语义双重判断

### 打断机制
- Silero VAD 检测人声
- 能量检测 + 频谱分析区分人声和噪音
- 持续 150ms 以上才算打断
- 打断后立即停止播放，切换到监听

### 离线备用
- 网络断开时自动切换到本地 Vosk
- 本地 Silero VAD 持续工作

## 虚拟桌面工作区

### 架构
- 在 macOS Spaces 中创建 Jarvis 专用桌面
- Agent 在独立 Space 中执行任务
- 不干扰用户当前桌面

### 进度显示
- 灵动岛显示圆圈进度动画
- 悬浮时显示实时视频预览
- 预览中显示小白鼠标指针标识操作位置

## 长时间工作机制

### 检查点机制
- 每个关键步骤创建检查点
- 保存截图和状态
- 支持回滚到检查点

### 崩溃恢复
- 30秒自动保存
- 崩溃后自动恢复
- 通知用户未完成的任务

## MCP 配置

```json
{
  "mcpServers": {
    "electron": {
      "command": "npx",
      "args": ["-y", "electron-mcp-server"],
      "env": {
        "SECURITY_LEVEL": "development"
      }
    },
    "context7": {
      "type": "http",
      "url": "https://mcp.context7.com/mcp"
    }
  }
}
```
